---
title: "Projet MRR - Bio"
author: "Teddy ALEXANDRE, Arthur BABIN, Binôme 9"
date: "12 Décembre 2022"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(corrplot)
library(lars)
library(MASS)
library(caret)
library(ggplot2)
library(lattice)
library(tidyverse)
library(glmnet)
```


```{r}
## load data
load(file="/home/talexandre/Bureau/MRR/Projet/projet-mrr-2022-bio/Ressources/project_park.RData")
dim(geno.df)
dim(pheno.df)
dim(Xmat)
```

```{r}
X = Xmat
Y1 = data.matrix(pheno.df$Seed.number.per.panicle)

# Replace NA Values bY11 the mean of each column
for(i in 1:ncol(X)){
  X[is.na(X[,i]), i] <- round(mean(X[,i], na.rm = TRUE))
}
Y1[is.na(Y1)] = mean(Y1, na.rm=TRUE)


# We reduce the size of X
X = X[,sample(x = 1:36901, size=36901)]
random_sample = createDataPartition(Y1, p = 0.8, list = FALSE)
X_train = X[random_sample,]
Y1_train = Y1[random_sample]

X_test = X[-random_sample,]
Y1_test = Y1[-random_sample]

dim(Xmat)
```


```{r}
#Regular regression
#modreg = lm(Y1_train ~., data = as.data.frame(X_train))
#summarY1(modreg)
cor = cor(X[1:30,1:30])
corrplot(cor)
```



```{r}
# Utils
# Calcule le meilleur lambda issu d'une régression Lasso (alpha = 1)
findBestLambda <- function(inputs,outputs,alphaPen) {
  lambdas <- 10^seq(2, -3, by = -.1)
  
  #k-fold cross validation to determine the best lambda
  reg <- cv.glmnet(inputs, outputs, alpha = alphaPen, lambda = lambdas, 
                   standardize = FALSE, nfolds = 15, type.measure="mse")
  plot(reg)
  plot(reg$glmnet.fit, "lambda", label=TRUE)
  
  
  # Best lambda obtained from cross-validation
  lambda_best <- reg$lambda.min; #or 1se
  abline(v=log(lambda_best),col="red")
  text(log(lambda_best)+0.5 ,20, "log(lambda_best)", srt=0.2, col = "red",pos=4)
  lambda_best
}

makePredictionsPen <- function(model,testInputs,bestLambda) {
  predictions <- predict.glmnet(model, s = bestLambda, newx = testInputs)
  predictions
}

# Calcule les métriques importantes : R2, RSE et MAE
computeMetrics <- function(predictions,testOutputs,modelName) {
  metrics <- data.frame(
    Model = modelName,
    R2 = R2(predictions, testOutputs),
    RMSE = RMSE(predictions, testOutputs),
    MAE = MAE(predictions, testOutputs)
    )
  colnames(metrics) <- c('Model Name', 'R2','RMSE','MAE')
  metrics
}
```



```{r}
# Régression LASSO (alpha = 1 dans glmnet)
processPenalization <- function(X_train, Y_train, X_test, Y_test, alphaPen) {
  lambda_best <- findBestLambda(X_train,Y_train,alphaPen)
  modpen <- glmnet(X_train, Y_train, alpha = alphaPen, lambda = lambda_best, standardize = FALSE)
  
  pred_train <- makePredictionsPen(modpen, X_train, lambda_best)
  pred_test <- makePredictionsPen(modpen, X_test, lambda_best)
  text_train = ""
  text_test = ""
  if (alphaPen == 1) {
    text_train = "Lasso (on train)"
    text_test = "Lasso (on test)"
  }
  else if (alphaPen == 0) {
    text_train = "Ridge (on train)"
    text_test = "Ridge (on test)"
  }
  else {
    text_train = "Elastic-Net (on train)"
    text_test = "Elastic-Net (on test)"
  }
  res_train <- computeMetrics(pred_train,Y_train,text_train)
  res_test <- computeMetrics(pred_test,Y_test,text_test)
  
  coef(modpen)
  
  print(rbind(res_train, res_test))
  return(c(pred_train, pred_test))
}
```

```{r}
# Seed.number.per.panicle
#processPenalization(X_train, Y1_train, X_test, Y1_test, alphaPen = 1)
```

```{r}
Y2 = pheno.df$Straighthead.suseptability
Y2[is.na(Y2)] = mean(Y2, na.rm=TRUE)
Y2_train = Y2[random_sample]
Y2_test = Y2[-random_sample]
```
```{r}
# Straighthead.Suseptability
#processPenalization(X_train, Y2_train, X_test, Y2_test, alpha = 1)
```

```{r}
Y3 = pheno.df$Amylose.content
Y3[is.na(Y3)] = mean(Y3, na.rm=TRUE)
Y3_train = Y3[random_sample]
Y3_test = Y3[-random_sample]
```
```{r}
# Lasso
Y1_pred = processPenalization(X_train, Y3_train, X_test, Y3_test, alphaPen = 1)[1]
```


```{r}
# Elastic-Net
for (alpha in c(0.2,0.4,0.6,0.8))
  processPenalization(X_train, Y3_train, X_test, Y3_test, alphaPen = alpha)
```



