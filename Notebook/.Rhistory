load("/home/talexandre/Bureau/S3 MRR/Projet/projet-mrr-2022-bio/Ressources/project_park.RData")
View(pheno.df)
View(geno.df)
View(Xmat)
knitr::opts_chunk$set(echo = TRUE)
library(corrplot)
library(lars)
library(MASS)
library(caret)
library(ggplot2)
library(lattice)
library(tidyverse)
library(glmnet)
## load data
load(file="/home/talexandre/Bureau/MRR/Projet/projet-mrr-2022-bio/Ressources/project_park.RData")
dim(geno.df)
dim(pheno.df)
dim(Xmat)
X = Xmat
Y1 = data.matrix(pheno.df$Seed.number.per.panicle)
# Replace NA Values bY11 the mean of each column
for(i in 1:ncol(X)){
X[is.na(X[,i]), i] <- round(mean(X[,i], na.rm = TRUE))
}
Y1[is.na(Y1)] = mean(Y1, na.rm=TRUE)
# We reduce the size of X
X = X[,sample(x = 1:36901, size=36901)]
random_sample = createDataPartition(Y1, p = 0.8, list = FALSE)
X_train = X[random_sample,]
Y1_train = Y1[random_sample]
X_test = X[-random_sample,]
Y1_test = Y1[-random_sample]
dim(Xmat)
#Regular regression
#modreg = lm(Y1_train ~., data = as.data.frame(X_train))
#summarY1(modreg)
cor = cor(X[1:30,1:30])
corrplot(cor)
# Utils
# Calcule le meilleur lambda issu d'une régression Lasso
findBestLassoLambda <- function(inputs,outputs) {
lambdas <- 10^seq(2, -5, by = -.1)
#k-fold cross validation to determine the best lambda
reg <- cv.glmnet(inputs, outputs, alpha = 1, lambda = lambdas,
standardize = TRUE, nfolds = 20,tY1pe.measure="mse")
plot(reg)
plot(reg$glmnet.fit, "lambda")
# Best
lambda_best <- reg$lambda.min; #or 1se
abline(v=log(lambda_best),col="red")
text(log(lambda_best)+0.5 ,20, "log(lambda_best)", srt=0.2, col = "red",pos=4)
lambda_best
}
makePredictionsLasso <- function(model,testInputs,bestLambda) {
predictions <- predict.glmnet(model, s = bestLambda, newx = testInputs);
predictions;
}
# Calcule les métriques importantes : R2, RSE et MAE
computeMetrics <- function(predictions,testOutputs,modelName) {
metrics <- data.frame(
Model = modelName,
R2 = R2(predictions, testOutputs),
RMSE = RMSE(predictions, testOutputs),
MAE = MAE(predictions, testOutputs)
);
colnames(metrics) <- c('Model Name', 'R2','RMSE','MAE')
metrics;
}
# Régression LASSO (alpha = 1 dans glmnet)
processLasso <- function(X_train, Y_train, X_test, Y_test) {
lassolambda_best <- findBestLassoLambda(X_train,Y_train)
modlasso <- glmnet(X_train, Y_train, alpha = 1, lambda = lassolambda_best, standardize = TRUE)
predlasso_train <- makePredictionsLasso(modlasso, X_train, lassolambda_best)
predlasso_test <- makePredictionsLasso(modlasso, X_test, lassolambda_best)
reslasso_train <- computeMetrics(predlasso_train,Y_train,"Lasso (on train)")
reslasso_test <- computeMetrics(predlasso_test,Y_test,"Lasso (on test)")
coef(modlasso)
print(rbind(reslasso_train, reslasso_test))
return(c(predlasso_train, predlasso_test))
}
#processLasso(X_train, Y1_train, X_test, Y1_test)
Y1_pred = processLasso(X_train, Y1_train, X_test, Y1_test)[2]
plot(Y1_pred, Y1_test)
Y2 = pheno.df$Straighthead.suseptability
Y2[is.na(Y2)] = mean(Y2, na.rm=TRUE)
Y2_train = Y2[random_sample]
Y2_test = Y2[-random_sample]
processLasso(X_train, Y2_train, X_test, Y2_test)
Y3 = pheno.df$Amylose.content
Y3[is.na(Y3)] = mean(Y3, na.rm=TRUE)
Y3_train = Y3[random_sample]
Y3_test = Y3[-random_sample]
processLasso(X_train, Y3_train, X_test, Y3_test)
knitr::opts_chunk$set(echo = TRUE)
library(corrplot)
library(lars)
library(MASS)
library(caret)
library(ggplot2)
library(lattice)
library(tidyverse)
library(glmnet)
## load data
load(file="/home/talexandre/Bureau/MRR/Projet/projet-mrr-2022-bio/Ressources/project_park.RData")
dim(geno.df)
dim(pheno.df)
dim(Xmat)
X = Xmat
Y1 = data.matrix(pheno.df$Seed.number.per.panicle)
# Replace NA Values bY11 the mean of each column
for(i in 1:ncol(X)){
X[is.na(X[,i]), i] <- round(mean(X[,i], na.rm = TRUE))
}
Y1[is.na(Y1)] = mean(Y1, na.rm=TRUE)
# We reduce the size of X
X = X[,sample(x = 1:36901, size=36901)]
random_sample = createDataPartition(Y1, p = 0.8, list = FALSE)
X_train = X[random_sample,]
Y1_train = Y1[random_sample]
X_test = X[-random_sample,]
Y1_test = Y1[-random_sample]
dim(Xmat)
#Regular regression
#modreg = lm(Y1_train ~., data = as.data.frame(X_train))
#summarY1(modreg)
cor = cor(X[1:30,1:30])
corrplot(cor)
# Utils
# Calcule le meilleur lambda issu d'une régression Lasso
findBestLassoLambda <- function(inputs,outputs) {
lambdas <- 10^seq(2, -5, by = -.1)
#k-fold cross validation to determine the best lambda
reg <- cv.glmnet(inputs, outputs, alpha = 1, lambda = lambdas,
standardize = TRUE, nfolds = 20,tY1pe.measure="mse")
plot(reg)
plot(reg$glmnet.fit, "lambda")
# Best
lambda_best <- reg$lambda.min; #or 1se
abline(v=log(lambda_best),col="red")
text(log(lambda_best)+0.5 ,20, "log(lambda_best)", srt=0.2, col = "red",pos=4)
lambda_best
}
makePredictionsLasso <- function(model,testInputs,bestLambda) {
predictions <- predict.glmnet(model, s = bestLambda, newx = testInputs);
predictions;
}
# Calcule les métriques importantes : R2, RSE et MAE
computeMetrics <- function(predictions,testOutputs,modelName) {
metrics <- data.frame(
Model = modelName,
R2 = R2(predictions, testOutputs),
RMSE = RMSE(predictions, testOutputs),
MAE = MAE(predictions, testOutputs)
);
colnames(metrics) <- c('Model Name', 'R2','RMSE','MAE')
metrics;
}
# Régression LASSO (alpha = 1 dans glmnet)
processLasso <- function(X_train, Y_train, X_test, Y_test) {
lassolambda_best <- findBestLassoLambda(X_train,Y_train)
modlasso <- glmnet(X_train, Y_train, alpha = 1, lambda = lassolambda_best, standardize = TRUE)
predlasso_train <- makePredictionsLasso(modlasso, X_train, lassolambda_best)
predlasso_test <- makePredictionsLasso(modlasso, X_test, lassolambda_best)
reslasso_train <- computeMetrics(predlasso_train,Y_train,"Lasso (on train)")
reslasso_test <- computeMetrics(predlasso_test,Y_test,"Lasso (on test)")
coef(modlasso)
print(rbind(reslasso_train, reslasso_test))
return(c(predlasso_train, predlasso_test))
}
#processLasso(X_train, Y1_train, X_test, Y1_test)
Y1_pred = processLasso(X_train, Y1_train, X_test, Y1_test)[2]
plot(Y1_pred, Y1_test)
knitr::opts_chunk$set(echo = TRUE)
library(corrplot)
library(lars)
library(MASS)
library(caret)
library(ggplot2)
library(lattice)
library(tidyverse)
library(glmnet)
## load data
load(file="/home/talexandre/Bureau/MRR/Projet/projet-mrr-2022-bio/Ressources/project_park.RData")
dim(geno.df)
dim(pheno.df)
dim(Xmat)
X = Xmat
Y1 = data.matrix(pheno.df$Seed.number.per.panicle)
# Replace NA Values bY11 the mean of each column
for(i in 1:ncol(X)){
X[is.na(X[,i]), i] <- round(mean(X[,i], na.rm = TRUE))
}
Y1[is.na(Y1)] = mean(Y1, na.rm=TRUE)
# We reduce the size of X
X = X[,sample(x = 1:36901, size=36901)]
random_sample = createDataPartition(Y1, p = 0.8, list = FALSE)
X_train = X[random_sample,]
Y1_train = Y1[random_sample]
X_test = X[-random_sample,]
Y1_test = Y1[-random_sample]
dim(Xmat)
#Regular regression
#modreg = lm(Y1_train ~., data = as.data.frame(X_train))
#summarY1(modreg)
cor = cor(X[1:30,1:30])
corrplot(cor)
# Utils
# Calcule le meilleur lambda issu d'une régression Lasso
findBestLassoLambda <- function(inputs,outputs) {
lambdas <- 10^seq(2, -5, by = -.1)
#k-fold cross validation to determine the best lambda
reg <- cv.glmnet(inputs, outputs, alpha = 1, lambda = lambdas,
standardize = TRUE, nfolds = 20,tY1pe.measure="mse")
plot(reg)
plot(reg$glmnet.fit, "lambda")
# Best
lambda_best <- reg$lambda.min; #or 1se
abline(v=log(lambda_best),col="red")
text(log(lambda_best)+0.5 ,20, "log(lambda_best)", srt=0.2, col = "red",pos=4)
lambda_best
}
makePredictionsLasso <- function(model,testInputs,bestLambda) {
predictions <- predict.glmnet(model, s = bestLambda, newx = testInputs);
predictions;
}
# Calcule les métriques importantes : R2, RSE et MAE
computeMetrics <- function(predictions,testOutputs,modelName) {
metrics <- data.frame(
Model = modelName,
R2 = R2(predictions, testOutputs),
RMSE = RMSE(predictions, testOutputs),
MAE = MAE(predictions, testOutputs)
);
colnames(metrics) <- c('Model Name', 'R2','RMSE','MAE')
metrics;
}
# Régression LASSO (alpha = 1 dans glmnet)
processLasso <- function(X_train, Y_train, X_test, Y_test) {
lassolambda_best <- findBestLassoLambda(X_train,Y_train)
modlasso <- glmnet(X_train, Y_train, alpha = 1, lambda = lassolambda_best, standardize = TRUE)
predlasso_train <- makePredictionsLasso(modlasso, X_train, lassolambda_best)
predlasso_test <- makePredictionsLasso(modlasso, X_test, lassolambda_best)
reslasso_train <- computeMetrics(predlasso_train,Y_train,"Lasso (on train)")
reslasso_test <- computeMetrics(predlasso_test,Y_test,"Lasso (on test)")
coef(modlasso)
print(rbind(reslasso_train, reslasso_test))
return(c(predlasso_train, predlasso_test))
}
#processLasso(X_train, Y1_train, X_test, Y1_test)
Y1_pred = processLasso(X_train, Y1_train, X_test, Y1_test)[2]
plot(Y1_pred, Y1_test)
# Régression LASSO (alpha = 1 dans glmnet)
processLasso <- function(X_train, Y_train, X_test, Y_test) {
lassolambda_best <- findBestLassoLambda(X_train,Y_train)
modlasso <- glmnet(X_train, Y_train, alpha = 1, lambda = lassolambda_best, standardize = FALSE)
predlasso_train <- makePredictionsLasso(modlasso, X_train, lassolambda_best)
predlasso_test <- makePredictionsLasso(modlasso, X_test, lassolambda_best)
reslasso_train <- computeMetrics(predlasso_train,Y_train,"Lasso (on train)")
reslasso_test <- computeMetrics(predlasso_test,Y_test,"Lasso (on test)")
coef(modlasso)
print(rbind(reslasso_train, reslasso_test))
return(c(predlasso_train, predlasso_test))
}
#processLasso(X_train, Y1_train, X_test, Y1_test)
Y1_pred = processLasso(X_train, Y1_train, X_test, Y1_test)[2]
plot(Y1_pred, Y1_test)
Y2 = pheno.df$Straighthead.suseptability
Y2[is.na(Y2)] = mean(Y2, na.rm=TRUE)
Y2_train = Y2[random_sample]
Y2_test = Y2[-random_sample]
processLasso(X_train, Y2_train, X_test, Y2_test)
